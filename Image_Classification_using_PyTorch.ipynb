{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWdCpLcGhH3_"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "sUchZhcGqVZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor,Lambda,Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "L9Dkf_Iwqicg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dowload Data\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "M4540WKYrxBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data,batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "yldPGXuttKyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader"
      ],
      "metadata": {
        "id": "nGMtoLtIuLci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in test_dataloader:\n",
        "  print(x,y)"
      ],
      "metadata": {
        "id": "zmcJ3NgRvArk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else  \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "K1pI-Vg6vMlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define our custome Model\n",
        "\n",
        "class NeuralNetworks(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetworks,self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "sTRz8gj4wAaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "8KHTSJDE77S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetworks().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "GJ9nrl6N_ape"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 1e-3)\n"
      ],
      "metadata": {
        "id": "U1d1jF5X_pgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train loop\n",
        "\n",
        "def train(DataLoader,model,loss_fn,optimizer):\n",
        "  size = len(DataLoader.dataset)\n",
        "  model.train()\n",
        "  for batch,(X,y) in enumerate(DataLoader):\n",
        "    X,y = X.to(device),y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss,current = loss.item(),batch*len(X)\n",
        "      print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "EukLornUEgN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(DataLoader,model,loss_fn):\n",
        "  size = len(DataLoader.dataset)\n",
        "  num_batches = len(DataLoader)\n",
        "  model.eval()\n",
        "  test_loss,correct = 0,0\n",
        "  with torch.no_grad():\n",
        "    for batch,(X,y) in enumerate(DataLoader):\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")"
      ],
      "metadata": {
        "id": "qFncAzLrk7D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Start training\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n -----------------------------\")\n",
        "  train(train_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader,model,loss_fn)\n",
        "\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "id": "0j8ihe_qoXIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Save model\n",
        "torch.save(model.state_dict(),\"model.pth\")\n",
        "print(\"Model saved\")"
      ],
      "metadata": {
        "id": "tcBrjYMGrM2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetworks()\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\"))"
      ],
      "metadata": {
        "id": "LxU-i0sks59G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction classes\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\"\n",
        "]"
      ],
      "metadata": {
        "id": "w7KyJFFCtVYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(classes)"
      ],
      "metadata": {
        "id": "yEdXCCw9uwCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "ODo58x5Xu0AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y= test_data[0][0],test_data[0][1]\n",
        "x,y"
      ],
      "metadata": {
        "id": "GOsqcDiMu7bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "fGDAeRAPvDHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  pred = model(x)\n",
        "  predicted,actual = classes[pred[0].argmax(0)],classes[y]\n",
        "  print(f'Predicted :\"{predicted}\",Actual: \"{actual}\"')"
      ],
      "metadata": {
        "id": "6Nqu8NhyzqtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "# Loop through the training dataloader to get a batch\n",
        "\n",
        "for images,labels in train_dataloader:\n",
        "  break # Get the first batch and exit loop\n",
        "# Convert the images to numpy arrays\n",
        "images = images.numpy()\n",
        "# Plot the images\n",
        "fig,axes = plt.subplots(nrows=4,ncols=4,figsize=(10,10))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "  # Display the image\n",
        "  ax.imshow(np.transpose(images[i],(1,2,0)))\n",
        "  ax.set_title(f\"Label:{labels[i].item()}\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7HKRe4Xu0nFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhg4LW2_5jv1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}